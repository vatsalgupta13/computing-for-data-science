{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/restaurant-revenue-prediction/leaderboard.csv\n",
      "/kaggle/input/restaurant-revenue-prediction/train.csv\n",
      "/kaggle/input/restaurant-revenue-prediction/sampleSubmission.csv\n",
      "/kaggle/input/restaurant-revenue-prediction/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pandas import DataFrame\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold # 追加\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   Open Date        City  City Group Type  P1   P2   P3   P4  P5  ...  \\\n",
      "0   0  07/17/1999    İstanbul  Big Cities   IL   4  5.0  4.0  4.0   2  ...   \n",
      "1   1  02/14/2008      Ankara  Big Cities   FC   4  5.0  4.0  4.0   1  ...   \n",
      "2   2  03/09/2013  Diyarbakır       Other   IL   2  4.0  2.0  5.0   2  ...   \n",
      "3   3  02/02/2012       Tokat       Other   IL   6  4.5  6.0  6.0   4  ...   \n",
      "4   4  05/09/2009   Gaziantep       Other   IL   3  4.0  3.0  4.0   2  ...   \n",
      "\n",
      "   P29  P30  P31  P32  P33  P34  P35  P36  P37    revenue  \n",
      "0  3.0    5    3    4    5    5    4    3    4  5653753.0  \n",
      "1  3.0    0    0    0    0    0    0    0    0  6923131.0  \n",
      "2  3.0    0    0    0    0    0    0    0    0  2055379.0  \n",
      "3  7.5   25   12   10    6   18   12   12    6  2675511.0  \n",
      "4  3.0    5    1    3    2    3    4    3    3  4316715.0  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "df_trainval = pd.read_csv('/kaggle/input/restaurant-revenue-prediction/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/restaurant-revenue-prediction/test.csv')\n",
    "print(df_trainval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = df_trainval['revenue']\n",
    "del df_trainval['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Open Date  City  City Group  Type  P1   P2   P3   P4  P5  ...  P31  \\\n",
      "0   0 1999-07-17    60           1     1   4  5.0  4.0  4.0   2  ...    3   \n",
      "1   1 2008-02-14     4           1     0   4  5.0  4.0  4.0   1  ...    0   \n",
      "2   2 2013-03-09    14           0     1   2  4.0  2.0  5.0   2  ...    0   \n",
      "3   3 2012-02-02    52           0     1   6  4.5  6.0  6.0   4  ...   12   \n",
      "4   4 2009-05-09    21           0     1   3  4.0  3.0  4.0   2  ...    1   \n",
      "\n",
      "   P32  P33  P34  P35  P36  P37  Year  Month  Day  \n",
      "0    4    5    5    4    3    4  1999      7   17  \n",
      "1    0    0    0    0    0    0  2008      2   14  \n",
      "2    0    0    0    0    0    0  2013      3    9  \n",
      "3   10    6   18   12   12    6  2012      2    2  \n",
      "4    3    2    3    4    3    3  2009      5    9  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat([df_trainval,df_test],axis=0)\n",
    "df_all['Open Date'] = pd.to_datetime(df_all[\"Open Date\"])\n",
    "df_all['Year'] = df_all['Open Date'].apply(lambda x:x.year)\n",
    "df_all['Month'] = df_all['Open Date'].apply(lambda x:x.month)\n",
    "df_all['Day'] = df_all['Open Date'].apply(lambda x:x.day)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_all['City'] = le.fit_transform(df_all['City'])\n",
    "df_all['City Group'] = df_all['City Group'].map({'Other':0,'Big Cities':1})\n",
    "df_all[\"Type\"] = df_all[\"Type\"].map({\"FC\":0, \"IL\":1, \"DT\":2, \"MB\":3})\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainval = df_all.iloc[:df_trainval.shape[0]]\n",
    "df_test = df_all.iloc[df_trainval.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_col = [col for col in df_trainval.columns if col not in ['Id','Open Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "ms = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0    1    2         3         4         5         6         7   \\\n",
      "0  0.967742  1.0  0.5  0.272727  0.615385  0.533333  0.222222  0.142857   \n",
      "1  0.064516  1.0  0.0  0.272727  0.615385  0.533333  0.222222  0.000000   \n",
      "2  0.225806  0.0  0.5  0.090909  0.461538  0.266667  0.444444  0.142857   \n",
      "3  0.838710  0.0  0.5  0.454545  0.538462  0.800000  0.666667  0.428571   \n",
      "4  0.338710  0.0  0.5  0.181818  0.461538  0.400000  0.222222  0.142857   \n",
      "\n",
      "         8         9   ...        33    34        35        36        37  \\\n",
      "0  0.111111  0.444444  ...  0.200000  0.16  0.833333  0.208333  0.266667   \n",
      "1  0.111111  0.444444  ...  0.000000  0.00  0.000000  0.000000  0.000000   \n",
      "2  0.222222  0.444444  ...  0.000000  0.00  0.000000  0.000000  0.000000   \n",
      "3  0.333333  1.000000  ...  0.800000  0.40  1.000000  0.750000  0.800000   \n",
      "4  0.111111  0.444444  ...  0.066667  0.12  0.333333  0.125000  0.266667   \n",
      "\n",
      "     38     39        40        41        42  \n",
      "0  0.15  0.500  0.166667  0.545455  0.533333  \n",
      "1  0.00  0.000  0.666667  0.090909  0.433333  \n",
      "2  0.00  0.000  0.944444  0.181818  0.266667  \n",
      "3  0.60  0.750  0.888889  0.090909  0.033333  \n",
      "4  0.15  0.375  0.722222  0.363636  0.266667  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "df_trainval_sc = sc.fit_transform(df_trainval[df_train_col])\n",
    "df_trainval_sc_ms = ms.fit_transform(df_trainval_sc)\n",
    "print(DataFrame(df_trainval_sc_ms).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_cv():\n",
    "    m_train = np.floor(len(rev)*0.75).astype(int)#このキャストをintにしないと後にハマる\n",
    "    train_indices = np.arange(m_train)\n",
    "    test_indices = np.arange(m_train, len(rev))\n",
    "    yield (train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter =  {'C': 10.0, 'epsilon': 0.1}\n",
      "accuracy =  -0.029186054898893588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_cnt = 20\n",
    "params = {\"C\":np.logspace(0,1,params_cnt), \"epsilon\":np.logspace(-1,1,params_cnt)}\n",
    "gridsearch = GridSearchCV(SVR(kernel=\"linear\"), params, cv=gen_cv(), scoring=\"r2\", return_train_score=True)\n",
    "gridsearch.fit(df_trainval_sc_ms, rev)\n",
    "print('The best parameter = ',gridsearch.best_params_)\n",
    "print('accuracy = ',gridsearch.best_score_)\n",
    "print()\n",
    "\n",
    "regr = SVR(kernel=\"linear\", C=gridsearch.best_params_[\"C\"], epsilon=gridsearch.best_params_[\"epsilon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models_mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8426a962c431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel_svr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmodels_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmodels_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_rf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodels_svr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_svr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models_mlp' is not defined"
     ]
    }
   ],
   "source": [
    "splits = 5\n",
    "kf = KFold(n_splits=splits,shuffle=True,random_state=0)\n",
    "\n",
    "mlp = MLPRegressor(activation='relu',\n",
    "                  solver='adam',\n",
    "                  batch_size=100,\n",
    "                  max_iter=2000,\n",
    "                   hidden_layer_sizes=(16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,)\n",
    "                  )\n",
    "rf = RandomForestRegressor(n_estimators=1000,\n",
    "                           max_depth=30,\n",
    "                           random_state=0,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "rmse_list = []\n",
    "#models_mlp = []\n",
    "#models_rf = []\n",
    "#models_svr = []\n",
    "for train_index,test_index in kf.split(df_trainval_sc_ms):\n",
    "    X_train = df_trainval.iloc[train_index]\n",
    "    Y_train = rev.iloc[train_index]\n",
    "    X_valid = df_trainval.iloc[test_index]\n",
    "    Y_valid = rev.iloc[test_index]\n",
    "    model_mlp = mlp.fit(X_train[df_train_col], Y_train)\n",
    "    model_rf = rf.fit(X_train[df_train_col], Y_train)\n",
    "    model_svr = regr.fit(X_train[df_train_col], Y_train)\n",
    "    models_mlp.append(model_mlp)\n",
    "    models_rf.append(model_rf)\n",
    "    models_svr.append(model_svr)\n",
    "    prediction_rf = rf.predict(X_valid[df_train_col])\n",
    "    prediction_mlp = mlp.predict(X_valid[df_train_col])\n",
    "    prediction_regr = regr.predict(X_valid[df_train_col])\n",
    "    prediction = (prediction_rf + prediction_mlp + prediction_regr) / 3\n",
    "    val_rmse = mean_absolute_error(Y_valid,prediction)\n",
    "    print(val_rmse)\n",
    "    rmse_list.append(val_rmse)\n",
    "print('average rmse : {0}'.format(sum(rmse_list)/len(rmse_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sc = sc.transform(df_test[df_train_col])\n",
    "df_test_sc_ms = ms.fit_transform(df_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(df_trainval_sc_ms, rev)\n",
    "rf.fit(df_trainval_sc_ms, rev)\n",
    "regr.fit(df_trainval_sc_ms, rev)\n",
    "\n",
    "prediction_rf = rf.predict(df_test_sc_ms)\n",
    "prediction_mlp = mlp.predict(df_test_sc_ms)\n",
    "prediction_regr = regr.predict(df_test_sc_ms)\n",
    "\n",
    "prediction = (prediction_rf + prediction_mlp + prediction_regr) / 3\n",
    "\n",
    "submission = DataFrame({'Id':df_test.Id,'Prediction':prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  __output__.json  submission191019.csv\r\n",
      "/kaggle/working\r\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv('./submission191019.csv',index=False)\n",
    "!ls && pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
